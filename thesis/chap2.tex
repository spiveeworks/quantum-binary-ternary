% chap2.tex (Chapter 2 of the thesis)
\chapter[TERNARY ARITHMETIC]{Ternary Arithmetic}
\section{Ternary Logic}
Although these techniques about the polynomial algebra of ternary logic are novel and powerful, they were a secondary result of \cite{arithmetics}, whereas the main goal was to provide concrete circuits that could implement addition of ternary integers, since integer addition is central to arithmetic. [``Factoring with Qutrits'' is a big deal here, and has a lot of results that are hard to parse... they are surprising (metaplectic performs better than supermetaplectic, binary performs better than ternary in width-limited systems) but might be quite specific to the metaplectic architectures being considered by this group... I don't know if I have time to account for that paper properly, but it's a good one so it would be ideal if I did!] They provide two algorithms that both perform addition, but one requiring a larger amount of physical time to compute, [should define width vs depth] where the other uses parallel computation on a larger number of qutrits in order to perform the calculation faster.

These algorithms are implemented in ways that leverage coincidences of having exactly 3 dimensions, and exemplify what efficient ternary algorithms should look like, but they also raise the question of whether a mixed binary-ternary quantum computer could implement these algorithms more efficiently. In this section we give an overview of these algorithms as presented in \cite{arithmetics}, [their performance in the context of Shor's factoring algorithm as presented in ``Factoring with Qutrits'', and raise some basic questions about how all of these algorithms would look if implemented in a fault tolerant, mixed logic system. [ultimately providing motivation for the universality argument we give in chapter 3, and I think also providing motivation for fault tolerant implementation of our basis in a system that is physically ternary] [this is such a strong motivator, but I want to be careful that they haven't already talked about fault tolerance, like in the topological-anyon-thing paper, or if they have then be mindful of what they have said... post-hoc justification of things takes a lot of last minute reading!]

\ [also what part of it was `improved'? I think leveraging the binary nature of some of the variables was actually the main advantage!]
\subsection{Improved Ternary Arithmetics}
The classical implementation of binary addition is first to define a ``half adder'' which calculates the sum of two bits $a_0 + b_0$ as a number between 0 and 2, in binary either $00$, $01$, or $10$. We can observe that the least significant digit is simply $s_0 = a_0 + b_0 \mod 2$, and in the binary case the most significant digit is $a_0b_0$. This low digit is output directly, but the high digit is now named $c_1$ and `carried'. This leads to the ``full adder'' which calculates the sum of 3 bits $a_1 + b_1 + c_1$ as a number between 0 and 3. Both of these are classical operations which could be implemented as permutations in the usual way. In the ternary case the same logic applies, a ternary full adder would add 3 trits $a_1 + b_1 + c_1$ to get a number between 0 and 6, represented as two trits $c_2, s_1$, returning $s_1$ as a result, and carrying $c_2$ forward.

The first algorithm presented by \cite{arithmetics} leverages the fact that the only way $c_{i+1}$ can be 2 is if $a_i = b_i = c_i = 2$, but since $c_1$ comes from a half adder, or from $c_0$ which was initialized to 0, we know that $c_i$ will never be 0. This means that the carry operation implemented only needs to calculate $c_{i+1}$ in situations where $c_i$ is 0 or 1, the other 9 inputs can essentially produce garbage. Additionally they allow the circuit they implement $U_c$ to transform the registers containing $a_i$ and $b_i$, allowing all calculations to be made in place. The carry `trits' are calculated up to the highest trit $c_{l+1}$, which is yielded as is as $s_{l+1}$, then this calculation is reversed to recover $a_l$, $b_l$, and $c_l$, setting $s_l = a_l + b_l + c_l \mod 3$, and so on, overwriting $b_l$ with this value since it is no longer needed, down to $s_0 = a_0 + b_0 + c_0 \mod 3$. This algorithm acts on $2l+2$ qutrits, the digits $a_i$ and $b_i$, along with $c_0$ which is generally going to be 0, and $s_{l+1}$ which is initially also 0. This is only one or two qutrits more than the logical input of the algorithm, which is hard to beat, and uses $2n$ non-Clifford operations. (the ones implemented either asymptotically [or fault tolerantly using magic states])

The second algorithm aims to parallelise the calculation of the carry trits by observing three cases of $a_i + b_i + c_i$:
\begin{itemize}
	\item $a_i = b_i = 0 \implies c_{i+1} = 0$, denoted $C[i, i+1] = 0$
	\item $a_i + b_i = 1 \implies c_{i+1} = c_i$, denoted $C[i, i+1] = 2$
	\item $a_i + b_i \geq 2 \implies c_{i+1} = 1$, denoted $C[i, i+1] = 1$
\end{itemize}
These three cases can be calculated up front and stored in trit registers, without knowing any carry digits. This allows the calculations to be done in parallel, requiring $l$ Clifford gates, but taking the same amount of time that would be needed if $l = 1$.

Next a merge algorithm is defined, if $C[i, j] = C[j, k] = 2$ then $c_i = c_j = c_k$, so $C[i, k] = 2$ also. In fact whenever $C[j, k] = 2$ we will have $C[i, k] = C[i, j]$. On the other if $C[j, k] \neq 2$ then $c_k$ will be $C[j, k]$, 0 or 1 respectively, so $C[i, k]$ is simply $C[j, k]$. This is another classical operation, which can be implemented as a permutation. This allows for what is called a `divide and conquer' algorithm, where different $C[i, k]$ values are merged one layer at a time, taking $l - \omega(l) - \left\lfloor \log l \right\rfloor$ additional trits on top of the $2l$ needed for the input of the algorithm, where $\omega(l)$ is the number of 1s in the binary expansion of $l$. The `layers' add up to a circuit depth of $\left\lfloor \log l \right\rfloor + \left\lfloor \log \frac{n}{3} \right\rceil + 2$, despite the algorithm using $3l - 2\omega(l) - 2\left\lfloor \log l \right\rfloor - 1$ non-Clifford operations in total.

In addition to describing both of these algorithms in full, in a manner generic to any ternary quantum computer, the paper goes on to describe the standard ways of extending addition to implement addition mod $3^n$, as well as subtraction and comparison, and the efficiency gains that can be made by not calculating the data these calculations would only discard. Then of course the paper moves on to discuss the supermetaplectic basis as described previously.

While the algorithms it described are presented as ternary algorithms, it is interesting that the main optimization of the first algorithm was to recognize that the carry digit is actually a binary piece of data, making this algorithm a piece of mixed binary-ternary logic, simply embedded inside a ternary computer! Additionally the second algorithm has carry information $C[i, k]$ which is ternary, but this algorithm could be implemented for addition of binary integers as well! This means both of these algorithms could be interpreted as being intrinsically mixed, but as being embedded in a ternary quantum computer, even though they were intended to be intrinsically ternary algorithms. This makes the specific implementation of these algorithms in a mixed context an excellent starting point for thinking about real applications of mixed logic[, and also makes the efficiency discussions of ``Factoring with Qutrits'' a very interesting place to look for the tradeoffs between the binary and ternary roles of mixed quantum data].

\subsection{Fault Tolerance and Mixed Logic}
[outline fault tolerant computing in more detail, and outline how the ternary arithmetics algorithms act on physical qutrits, whereas a realistic algorithm would act on logical qutrits, and hence could be mixed.... I assume the topological quantum systems still need fault tolerant computing?]


\section{Porting ``Improved Ternary Arithmetics''}
[this stuff has been floating around for a while, will write the ideas here properly and integrate into the above]
We have discussed how the algorithms for arithmetic described in \cite{arithmetics} could naturally be ported to a mixed logic system, by using qubits for binary carry bits, or by using 

\begin{quantikz}
	\lstick{$c_i$} & \qw & \qw & \phase{1} \vqw{2} & \gate{S_{0,1}} & \qw \rstick{$c_{i+1}$} \\
	\lstick{$a_i$} & \gate[wires=2]{S_{00,22}} & \octrl{1} & \qw & \qw & \qw \\
	\lstick{$b_i$} & \qw & \targ{} & \gate{X_3^{-1}} & \phase{0} \vqw{-2} & \qw \\
\end{quantikz}

[don't know how to do $\oplus^\dagger$ so ugly box for now.]

have found a useful set of basic gates for mechanized compilation
\\let's look at specific algorithms that have been designed rather than compiled
\\\cite{arithmetics} implements ternary addition as a permutation on computational basis states
\\the ripple carry is designed so that the carry digit is always binary, which could be implemented in a mixed context
\\(possibly draw up a circuit implementing the carry operations)
\\the look ahead carry has ternary carry registers, but could be used for binary arithmetic, again giving a mixed algorithm
\\(possibly draw up circuit for this as well)
\\either of these would have less entropy than the pure ternary case, but many practical tradeoffs may render pure ternary to be superior, such as connectivity requirements, performance costs of mixed logic in general
\\we have access to any method, lot of flexibility! add bits or trits with bit carry or trit carry
\\(possibly mention mixed-string representations, here or in final discussion)

